# Model configuration

# Base model parameters
base_model:
  name: "gpt2"  # or another suitable model
  revision: "main"

# Tokenizer settings
tokenizer:
  max_length: 512
  padding: "max_length"
  truncation: true

# Generation parameters
generation:
  max_length: 100
  min_length: 10
  do_sample: true
  temperature: 0.7
  top_p: 0.9
  top_k: 50
  num_return_sequences: 1

# Fine-tuning parameters
fine_tuning:
  learning_rate: 5e-5
  num_train_epochs: 3
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  warmup_steps: 500
  weight_decay: 0.01

# Few-shot learning parameters
few_shot:
  max_examples: 5
  example_separator: "\n\n"

# Model quantization (if applicable)
quantization:
  enabled: false
  bits: 8

# Hardware acceleration
hardware:
  use_gpu: true
  precision: "float16"  # or "float32" for full precision
